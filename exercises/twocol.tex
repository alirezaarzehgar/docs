\documentclass[twocolumn,a4paper,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[width = 10cm]{geometry}

\begin{document}

Formalization

While Newton and Leibniz provided a systematic approach to integration, their work lacked a degree of rigour. Bishop Berkeley memorably attacked the vanishing increments used by Newton, calling them "ghosts of departed quantities".[11] Calculus acquired a firmer footing with the development of limits. Integration was first rigorously formalized, using limits, by Riemann.[12] Although all bounded piecewise continuous functions are Riemann-integrable on a bounded interval, subsequently more general functions were considered—particularly in the context of Fourier analysis—to which Riemann's definition does not apply, and Lebesgue formulated a different definition of integral, founded in measure theory (a subfield of real analysis). Other definitions of integral, extending Riemann's and Lebesgue's approaches, were proposed. These approaches based on the real number system are the ones most common today, but alternative approaches exist, such as a definition of integral as the standard part of an infinite Riemann sum, based on the hyperreal number system. 
Historical notation

The notation for the indefinite integral was introduced by Gottfried Wilhelm Leibniz in 1675.[13] He adapted the integral symbol, $\int$, from the letter $\int$ (long s), standing for summa  The modern notation for the definite integral, with limits above and below the integral sign, was first used by Joseph Fourier in Mémoires of the French Academy around 1819–1820, reprinted in his book of 1822.[14]

Isaac Newton used a small vertical bar above a variable to indicate integration, or placed the variable inside a box. The vertical bar was easily confused with .x or x, which are used to indicate differentiation, and the box notation was difficult for printers to reproduce, so these notations were not widely adopted.[15] 

Formalization

While Newton and Leibniz provided a systematic approach to integration, their work lacked a degree of rigour. Bishop Berkeley memorably attacked the vanishing increments used by Newton, calling them "ghosts of departed quantities".[11] Calculus acquired a firmer footing with the development of limits. Integration was first rigorously formalized, using limits, by Riemann.[12] Although all bounded piecewise continuous functions are Riemann-integrable on a bounded interval, subsequently more general functions were considered—particularly in the context of Fourier analysis—to which Riemann's definition does not apply, and Lebesgue formulated a different definition of integral, founded in measure theory (a subfield of real analysis). Other definitions of integral, extending Riemann's and Lebesgue's approaches, were proposed. These approaches based on the real number system are the ones most common today, but alternative approaches exist, such as a definition of integral as the standard part of an infinite Riemann sum, based on the hyperreal number system. 
Historical notation

The notation for the indefinite integral was introduced by Gottfried Wilhelm Leibniz in 1675.[13] He adapted the integral symbol, $\int$, from the letter $\int$ (long s), standing for summa  The modern notation for the definite integral, with limits above and below the integral sign, was first used by Joseph Fourier in Mémoires of the French Academy around 1819–1820, reprinted in his book of 1822.[14]

Isaac Newton used a small vertical bar above a variable to indicate integration, or placed the variable inside a box. The vertical bar was easily confused with .x or x, which are used to indicate differentiation, and the box notation was difficult for printers to reproduce, so these notations were not widely adopted.[15] 

Formalization

While Newton and Leibniz provided a systematic approach to integration, their work lacked a degree of rigour. Bishop Berkeley memorably attacked the vanishing increments used by Newton, calling them "ghosts of departed quantities".[11] Calculus acquired a firmer footing with the development of limits. Integration was first rigorously formalized, using limits, by Riemann.[12] Although all bounded piecewise continuous functions are Riemann-integrable on a bounded interval, subsequently more general functions were considered—particularly in the context of Fourier analysis—to which Riemann's definition does not apply, and Lebesgue formulated a different definition of integral, founded in measure theory (a subfield of real analysis). Other definitions of integral, extending Riemann's and Lebesgue's approaches, were proposed. These approaches based on the real number system are the ones most common today, but alternative approaches exist, such as a definition of integral as the standard part of an infinite Riemann sum, based on the hyperreal number system. 
Historical notation

The notation for the indefinite integral was introduced by Gottfried Wilhelm Leibniz in 1675.[13] He adapted the integral symbol, $\int$, from the letter $\int$ (long s), standing for summa  The modern notation for the definite integral, with limits above and below the integral sign, was first used by Joseph Fourier in Mémoires of the French Academy around 1819–1820, reprinted in his book of 1822.[14]

Isaac Newton used a small vertical bar above a variable to indicate integration, or placed the variable inside a box. The vertical bar was easily confused with .x or x, which are used to indicate differentiation, and the box notation was difficult for printers to reproduce, so these notations were not widely adopted.[15] 

Formalization

While Newton and Leibniz provided a systematic approach to integration, their work lacked a degree of rigour. Bishop Berkeley memorably attacked the vanishing increments used by Newton, calling them "ghosts of departed quantities".[11] Calculus acquired a firmer footing with the development of limits. Integration was first rigorously formalized, using limits, by Riemann.[12] Although all bounded piecewise continuous functions are Riemann-integrable on a bounded interval, subsequently more general functions were considered—particularly in the context of Fourier analysis—to which Riemann's definition does not apply, and Lebesgue formulated a different definition of integral, founded in measure theory (a subfield of real analysis). Other definitions of integral, extending Riemann's and Lebesgue's approaches, were proposed. These approaches based on the real number system are the ones most common today, but alternative approaches exist, such as a definition of integral as the standard part of an infinite Riemann sum, based on the hyperreal number system. 
Historical notation

The notation for the indefinite integral was introduced by Gottfried Wilhelm Leibniz in 1675.[13] He adapted the integral symbol, $\int$, from the letter $\int$ (long s), standing for summa  The modern notation for the definite integral, with limits above and below the integral sign, was first used by Joseph Fourier in Mémoires of the French Academy around 1819–1820, reprinted in his book of 1822.[14]

Isaac Newton used a small vertical bar above a variable to indicate integration, or placed the variable inside a box. The vertical bar was easily confused with .x or x, which are used to indicate differentiation, and the box notation was difficult for printers to reproduce, so these notations were not widely adopted.[15] 

\end{document}